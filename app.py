import streamlit as st
import pandas as pd
import plotly.express as px
import google.generativeai as genai
from langchain_google_genai import GoogleGenerativeAI
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_csv_agent
import os
import io

# T√≠tulo da p√°gina Streamlit
st.set_page_config(page_title="Agente de An√°lise de Dados para Detec√ß√£o de Fraudes", layout="wide")

#---
# Carregamento de credenciais da API do Gemini
# ---
# Obtenha sua chave de API do Gemini aqui: https://aistudio.google.com/app/apikey
# 1. Crie um arquivo chamado `.streamlit/secrets.toml` na mesma pasta do seu `app.py`.
# 2. Adicione a seguinte linha ao arquivo:
#    GEMINI_API_KEY = "sua_chave_aqui"
# A chave de API ser√° carregada automaticamente por este c√≥digo.

try:
    api_key = st.secrets["GEMINI_API_KEY"]
    os.environ['GOOGLE_API_KEY'] = api_key
    genai.configure(api_key=api_key)
except KeyError:
    st.error("Chave de API do Gemini n√£o encontrada. Por favor, adicione sua chave ao arquivo `.streamlit/secrets.toml`.")
    st.stop()


#---
# Configura√ß√£o da interface do usu√°rio
#---
st.title("Agente de An√°lise de Dados com IA para Fraudes de Cart√£o de Cr√©dito ü§ñüí≥")
st.markdown("Bem-vindo! Este agente de IA √© especializado em an√°lises de dados, Big Data e contabilidade. Ele pode responder a perguntas, gerar gr√°ficos e extrair conclus√µes de arquivos CSV, especialmente para detec√ß√£o de fraudes.")

# Instru√ß√µes de uso
st.info("""
    **Instru√ß√µes:**
    1.  O arquivo `creditcard.csv` j√° est√° carregado para demonstra√ß√£o.
    2.  Voc√™ pode fazer perguntas sobre os dados, como:
        -   `Qual a m√©dia da coluna 'Amount'?`
        -   `Quais s√£o os tipos de dados?`
        -   `Qual a correla√ß√£o entre as colunas 'Time' e 'Amount'?`
        -   `Mostre um histograma da coluna 'Class'.`
        -   `Quais as conclus√µes que voc√™ obteve a partir da an√°lise dos dados?`
""")


# ---
# Fun√ß√£o para criar e carregar o agente de IA
# ---
@st.cache_resource
def load_agent(df):
    """
    Cria e retorna um agente de LangChain que pode interagir com o DataFrame.
    """
    try:
        llm = GoogleGenerativeAI(model="gemini-pro")
        agent = create_csv_agent(
            llm=llm,
            path=df,
            verbose=True,
            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            allow_dangerous_code=True
        )
        return agent
    except Exception as e:
        st.error(f"Erro ao inicializar o agente de IA: {e}")
        return None

# Carregar o arquivo padr√£o para demonstra√ß√£o
@st.cache_data
def load_csv_data():
    """
    Carrega o arquivo creditcard.csv para demonstra√ß√£o.
    """
    # URL do arquivo creditcard.csv
    csv_url = "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
    try:
        # Nota: Como a URL do Kaggle √© uma p√°gina, n√£o o arquivo direto, usaremos um arquivo local
        # para a demonstra√ß√£o. Por favor, baixe o arquivo creditcard.csv e coloque na mesma pasta.
        df = pd.read_csv("creditcard.csv")
        return df
    except FileNotFoundError:
        st.error("Arquivo `creditcard.csv` n√£o encontrado. Por favor, baixe-o e coloque na mesma pasta do `app.py`.")
        st.stop()

# ---
# L√≥gica da interface e do chat
# ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibir mensagens anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["type"] == "text":
            st.markdown(message["content"])
        elif message["type"] == "plot":
            st.plotly_chart(message["content"])

# Carregar o DataFrame
df = load_csv_data()
if df is not None:
    agent = load_agent(df)

    if agent:
        # Demonstrar o agente com perguntas predefinidas
        demonstration_questions = [
            "Qual a m√©dia da coluna 'Amount'?",
            "Mostre um histograma da coluna 'Class'.",
            "Quais as vari√°veis que mais se correlacionam com a vari√°vel 'Amount'?",
            "Quais as conclus√µes que voc√™ obteve a partir da an√°lise deste conjunto de dados?",
        ]
        
        # Simular as respostas do agente para as perguntas de demonstra√ß√£o
        if "demonstration_done" not in st.session_state:
            st.session_state.demonstration_done = False
        
        if not st.session_state.demonstration_done:
            st.subheader("Demonstra√ß√£o das capacidades do agente")
            for q in demonstration_questions:
                with st.chat_message("user"):
                    st.markdown(q)
                
                # Simular a resposta do agente (isso pode levar um tempo)
                with st.chat_message("assistant"):
                    with st.spinner(f"Processando a pergunta: '{q}'..."):
                        if "hist" in q.lower():
                            response = agent.run(q)
                            # Assumir que a resposta gerar√° um gr√°fico
                            if 'plot' in response.lower():
                                fig = px.histogram(df, x="Class", title="Distribui√ß√£o da Vari√°vel 'Class'")
                                st.plotly_chart(fig)
                                st.session_state.messages.append({"role": "assistant", "content": fig, "type": "plot"})
                            else:
                                st.markdown(response)
                                st.session_state.messages.append({"role": "assistant", "content": response, "type": "text"})
                        else:
                            try:
                                response = agent.run(q)
                                st.markdown(response)
                                st.session_state.messages.append({"role": "assistant", "content": response, "type": "text"})
                            except Exception as e:
                                st.markdown(f"**Agente:** N√£o foi poss√≠vel responder a esta pergunta. Erro: {e}")
                                st.session_state.messages.append({"role": "assistant", "content": f"N√£o foi poss√≠vel responder a esta pergunta. Erro: {e}", "type": "text"})
            st.session_state.demonstration_done = True
            st.balloons()
            st.success("Demonstra√ß√£o conclu√≠da! Agora voc√™ pode fazer suas pr√≥prias perguntas.")

        # Campo de entrada para o usu√°rio
        if prompt := st.chat_input("Fa√ßa sua pergunta sobre os dados:"):
            st.session_state.messages.append({"role": "user", "content": prompt, "type": "text"})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("Analisando os dados..."):
                    try:
                        response = agent.run(prompt)
                        st.markdown(response)
                        st.session_state.messages.append({"role": "assistant", "content": response, "type": "text"})
                    except Exception as e:
                        st.markdown(f"**Agente:** N√£o foi poss√≠vel responder a esta pergunta. Erro: {e}")
                        st.session_state.messages.append({"role": "assistant", "content": f"N√£o foi poss√≠vel responder a esta pergunta. Erro: {e}", "type": "text"})
