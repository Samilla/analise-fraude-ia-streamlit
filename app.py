import streamlit as st
import pandas as pd
import os
import zipfile
import gzip
import json
from langchain_google_genai import ChatGoogleGenerativeAI
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
import hashlib
import numpy as np

# --- Configura√ß√µes Iniciais ---
st.set_page_config(layout="wide", page_title="Multi Agente de An√°lise Fiscal e de Fraudes")
pio.templates.default = "plotly_white"

# Modelo - Testando vers√µes dispon√≠veis
MODEL_NAME = "gemini-2.5-flash"  # Modelo mais est√°vel e universalmente dispon√≠vel

# API Key
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except (KeyError, AttributeError):
    API_KEY = os.environ.get("GEMINI_KEY", "")

if not API_KEY:
    st.error("ERRO: Chave da API do Gemini n√£o encontrada.")

# --- Fun√ß√µes de An√°lise Direta (SEM AGENT) ---
def analyze_dataframe(df):
    """Retorna an√°lise b√°sica do DataFrame"""
    analysis = {
        'shape': df.shape,
        'columns': df.columns.tolist(),
        'dtypes': df.dtypes.to_dict(),
        'missing': df.isnull().sum().to_dict(),
        'numeric_stats': df.describe().to_dict() if len(df.select_dtypes(include=['number']).columns) > 0 else {},
        'sample': df.head(5).to_dict('records')
    }
    return analysis

def execute_query_directly(df, query):
    """
    Executa queries diretamente no DataFrame sem usar agent
    Muito mais est√°vel e r√°pido
    """
    query_lower = query.lower()
    
    try:
        # Lista colunas
        if any(word in query_lower for word in ['coluna', 'colunas', 'lista', 'liste']):
            result = f"**Colunas do Dataset:**\n\n" + "\n".join([f"- {col}" for col in df.columns])
            return result, None
        
        # Conta linhas
        elif any(word in query_lower for word in ['quantas linhas', 'total de linhas', 'linhas tem', 'count', 'tamanho']):
            result = f"üìä **Total de linhas:** {len(df):,}\n**Total de colunas:** {len(df.columns)}"
            return result, None
        
        # Primeiras linhas
        elif any(word in query_lower for word in ['primeira', 'primeiras', 'head', 'mostr']):
            n = 5
            for word in query_lower.split():
                if word.isdigit():
                    n = int(word)
            result = f"**Primeiras {n} linhas:**\n\n"
            result += df.head(n).to_markdown(index=False)
            return result, None
        
        # Estat√≠sticas
        elif any(word in query_lower for word in ['estat√≠stica', 'estatistica', 'describe', 'resumo']):
            numeric_df = df.select_dtypes(include=['number'])
            if len(numeric_df.columns) > 0:
                result = "üìä **Estat√≠sticas Descritivas:**\n\n"
                result += numeric_df.describe().to_markdown()
                return result, None
            else:
                return "‚ö†Ô∏è N√£o h√° colunas num√©ricas no dataset.", None
        
        # Valores √∫nicos
        elif '√∫nico' in query_lower or 'unicos' in query_lower or 'unique' in query_lower:
            for col in df.columns:
                if col.lower() in query_lower:
                    unique_vals = df[col].nunique()
                    result = f"üìä **Coluna '{col}':**\n\n"
                    result += f"- Valores √∫nicos: {unique_vals:,}\n"
                    if unique_vals <= 20:
                        result += f"\n**Valores:**\n" + "\n".join([f"- {val}" for val in df[col].unique()])
                    return result, None
        
        # Correla√ß√£o
        elif 'correla√ß√£o' in query_lower or 'correlacao' in query_lower:
            cols_mentioned = [col for col in df.columns if col.lower() in query_lower]
            
            if len(cols_mentioned) >= 2:
                col1, col2 = cols_mentioned[0], cols_mentioned[1]
                if df[col1].dtype in ['int64', 'float64'] and df[col2].dtype in ['int64', 'float64']:
                    corr = df[col1].corr(df[col2])
                    
                    # Interpreta√ß√£o
                    if abs(corr) > 0.7:
                        strength = "forte"
                    elif abs(corr) > 0.4:
                        strength = "moderada"
                    else:
                        strength = "fraca"
                    
                    direction = "positiva" if corr > 0 else "negativa"
                    
                    result = f"üìä **Correla√ß√£o entre {col1} e {col2}:**\n\n"
                    result += f"- Valor: **{corr:.4f}**\n\n"
                    result += f"**üìà Interpreta√ß√£o:**\n"
                    result += f"A correla√ß√£o √© **{strength} e {direction}**. "
                    
                    if abs(corr) > 0.7:
                        result += f"Isso indica uma rela√ß√£o linear forte entre as vari√°veis."
                    elif abs(corr) > 0.4:
                        result += f"Existe uma rela√ß√£o moderada entre as vari√°veis."
                    else:
                        result += f"H√° pouca ou nenhuma rela√ß√£o linear entre as vari√°veis."
                    
                    return result, ('scatter', col1, col2)
            else:
                # Matriz de correla√ß√£o geral
                numeric_df = df.select_dtypes(include=['number'])
                if len(numeric_df.columns) >= 2:
                    corr_matrix = numeric_df.corr()
                    result = "üìä **Matriz de Correla√ß√£o:**\n\n"
                    result += corr_matrix.to_markdown()
                    return result, ('heatmap', None, None)
        
        # M√©dia
        elif 'm√©dia' in query_lower or 'media' in query_lower or 'mean' in query_lower:
            for col in df.columns:
                if col.lower() in query_lower:
                    if df[col].dtype in ['int64', 'float64']:
                        mean_val = df[col].mean()
                        std_val = df[col].std()
                        result = f"üìä **Estat√≠sticas de '{col}':**\n\n"
                        result += f"- M√©dia: **{mean_val:.2f}**\n"
                        result += f"- Desvio Padr√£o: **{std_val:.2f}**\n"
                        result += f"- M√≠nimo: {df[col].min():.2f}\n"
                        result += f"- M√°ximo: {df[col].max():.2f}\n"
                        return result, ('histogram', col, None)
        
        # Valores faltantes
        elif 'faltante' in query_lower or 'nulo' in query_lower or 'null' in query_lower or 'missing' in query_lower:
            missing = df.isnull().sum()
            missing = missing[missing > 0]
            if len(missing) > 0:
                result = "‚ö†Ô∏è **Valores Faltantes:**\n\n"
                for col, count in missing.items():
                    pct = (count / len(df)) * 100
                    result += f"- **{col}**: {count:,} ({pct:.2f}%)\n"
            else:
                result = "‚úÖ **N√£o h√° valores faltantes no dataset!**"
            return result, None
        
        # Distribui√ß√£o
        elif 'distribui√ß√£o' in query_lower or 'distribuicao' in query_lower:
            for col in df.columns:
                if col.lower() in query_lower:
                    if df[col].dtype in ['int64', 'float64']:
                        return f"üìä Distribui√ß√£o de **{col}**", ('histogram', col, None)
                    else:
                        counts = df[col].value_counts()
                        result = f"üìä **Distribui√ß√£o de '{col}':**\n\n"
                        result += counts.head(10).to_markdown()
                        return result, ('bar', col, None)
        
        # Fallback: usa LLM apenas para interpreta√ß√£o
        else:
            return None, None
            
    except Exception as e:
        return f"‚ùå Erro ao processar: {str(e)}", None

# --- Fun√ß√µes de Gr√°ficos ---
def create_chart(df, chart_info):
    """Cria gr√°ficos baseado no tipo e colunas"""
    if not chart_info:
        return None
    
    chart_type, col1, col2 = chart_info
    
    try:
        if chart_type == 'scatter' and col1 and col2:
            fig = px.scatter(df.head(1000), x=col1, y=col2,
                           title=f'üìä Rela√ß√£o entre {col1} e {col2}',
                           opacity=0.6)
            fig.update_layout(showlegend=False)
            return fig
        
        elif chart_type == 'histogram' and col1:
            fig = px.histogram(df, x=col1, nbins=30,
                             title=f'üìä Distribui√ß√£o de {col1}')
            fig.update_layout(showlegend=False)
            return fig
        
        elif chart_type == 'bar' and col1:
            counts = df[col1].value_counts().head(15)
            fig = px.bar(x=counts.index, y=counts.values,
                       labels={'x': col1, 'y': 'Contagem'},
                       title=f'üìä Top 15 - {col1}')
            fig.update_layout(xaxis_tickangle=-45, showlegend=False)
            return fig
        
        elif chart_type == 'heatmap':
            numeric_df = df.select_dtypes(include=['number'])
            corr = numeric_df.corr()
            fig = px.imshow(corr, text_auto=True, aspect="auto",
                          title='üìä Matriz de Correla√ß√£o',
                          color_continuous_scale='RdBu_r',
                          labels=dict(color="Correla√ß√£o"))
            return fig
            
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao criar gr√°fico: {e}")
        return None
    
    return None

def use_llm_for_complex_query(df, query):
    """Usa LLM apenas para queries complexas que n√£o podem ser resolvidas diretamente"""
    
    # Lista de modelos para tentar (em ordem de prioridade)
    models_to_try = [
        "gemini-pro",
        "models/gemini-pro",
        "gemini-1.5-flash",
        "models/gemini-1.5-flash",
        "gemini-1.5-pro",
        "models/gemini-1.5-pro"
    ]
    
    # Prepara contexto do DataFrame
    df_info = f"""Dataset Info:
- Linhas: {len(df)}
- Colunas: {', '.join(df.columns.tolist())}
- Tipos: {df.dtypes.to_dict()}

Primeiras 3 linhas:
{df.head(3).to_string()}

Estat√≠sticas b√°sicas:
{df.describe().to_string() if len(df.select_dtypes(include=['number']).columns) > 0 else 'Sem colunas num√©ricas'}
"""
    
    prompt = f"""{df_info}

Pergunta do usu√°rio: {query}

Instru√ß√µes:
1. Analise os dados fornecidos
2. Responda de forma clara e objetiva
3. Use markdown para formata√ß√£o
4. Se aplic√°vel, sugira visualiza√ß√µes

Resposta:"""
    
    # Tenta cada modelo at√© um funcionar
    for model_name in models_to_try:
        try:
            llm = ChatGoogleGenerativeAI(
                model=model_name,
                google_api_key=API_KEY,
                temperature=0.3,
                max_output_tokens=800,
                timeout=60
            )
            
            response = llm.invoke(prompt)
            return response.content
            
        except Exception as e:
            error_msg = str(e)
            # Se for erro 404, tenta pr√≥ximo modelo
            if "404" in error_msg or "not found" in error_msg.lower():
                continue
            # Se for outro erro, retorna mensagem
            else:
                return f"‚ùå Erro ao usar LLM: {error_msg[:200]}"
    
    # Se nenhum modelo funcionou
    return """‚ö†Ô∏è **N√£o foi poss√≠vel acessar o modelo Gemini.**

**Solu√ß√µes:**
1. Verifique sua API Key em: https://makersuite.google.com/app/apikey
2. Teste qual modelo est√° dispon√≠vel com o script de teste
3. Use perguntas diretas que n√£o precisam de LLM:
   - "Liste as colunas"
   - "Mostre estat√≠sticas"
   - "Correla√ß√£o entre X e Y"

üí° A maioria das an√°lises funcionam SEM precisar do LLM!"""

# --- Fun√ß√µes de Arquivo ---
def unzip_and_read_file(uploaded_file):
    """Descompacta e l√™ arquivos"""
    file_extension = uploaded_file.name.lower().split('.')[-1]
    uploaded_file.seek(0)
    
    try:
        if file_extension == 'zip':
            with zipfile.ZipFile(uploaded_file, 'r') as zf:
                csv_files = [name for name in zf.namelist() if name.endswith('.csv')]
                if not csv_files:
                    st.error("Nenhum arquivo CSV encontrado dentro do ZIP.")
                    return None
                with zf.open(csv_files[0]) as csv_file:
                    df = pd.read_csv(csv_file)
                    return df
                    
        elif uploaded_file.name.endswith(('.gz', '.gzip')):
            with gzip.open(uploaded_file, 'rt') as gz_file:
                df = pd.read_csv(gz_file)
                return df
                
        elif file_extension == 'csv':
            df = pd.read_csv(uploaded_file)
            return df
            
    except Exception as e:
        st.error(f"Erro ao processar o arquivo: {e}")
        return None
    
    return None

# --- Interface ---
st.title("ü§ñ Multi Agente de An√°lise Fiscal e de Fraudes")
st.markdown("---")

# Estados
if 'df' not in st.session_state:
    st.session_state.df = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'query_count' not in st.session_state:
    st.session_state.query_count = 0

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    st.metric("Perguntas realizadas", st.session_state.query_count)
    
    uploaded_file = st.file_uploader(
        "Carregue seu arquivo:",
        type=['csv', 'zip', 'gz'],
        key="file_uploader"
    )
    
    if st.button("üîÑ Reiniciar", use_container_width=True):
        st.session_state.df = None
        st.session_state.chat_history = []
        st.session_state.query_count = 0
        st.rerun()

# Processamento do arquivo
if uploaded_file and st.session_state.df is None:
    with st.spinner("Carregando arquivo..."):
        df = unzip_and_read_file(uploaded_file)
        
        if df is not None:
            st.session_state.df = df
            st.success(f"‚úÖ Arquivo '{uploaded_file.name}' carregado!")
            st.info(f"üìä Dataset: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas")
            st.info('üí° **Para iniciar, pergunte: "Liste as colunas"**')
            
            with st.expander("üëÄ Preview dos Dados"):
                st.dataframe(df.head(10), width='stretch')

# Chat
for role, message in st.session_state.chat_history:
    st.chat_message(role).markdown(message)

# Input
if st.session_state.df is not None:
    if prompt := st.chat_input("Fa√ßa sua pergunta..."):
        # Adiciona pergunta
        st.session_state.chat_history.append(("user", prompt))
        st.chat_message("user").markdown(prompt)
        
        with st.spinner("ü§ñ Analisando..."):
            # Tenta an√°lise direta (r√°pida e sem API)
            result, chart_info = execute_query_directly(st.session_state.df, prompt)
            
            # Se n√£o conseguiu responder diretamente, usa LLM
            if result is None:
                result = use_llm_for_complex_query(st.session_state.df, prompt)
                st.session_state.query_count += 1
            
            # Exibe resposta
            st.session_state.chat_history.append(("assistant", result))
            st.chat_message("assistant").markdown(result)
            
            # Cria gr√°fico se aplic√°vel
            if chart_info:
                chart = create_chart(st.session_state.df, chart_info)
                if chart:
                    st.plotly_chart(chart, use_container_width=True, key=f"chart_{len(st.session_state.chat_history)}")

else:
    st.info("‚ö†Ô∏è Carregue um arquivo CSV, ZIP ou GZ para iniciar.")